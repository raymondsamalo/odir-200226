{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aac0ba8",
   "metadata": {},
   "source": [
    "# Binocular\n",
    "\n",
    "We explore a different approach of training per patient by loading both left and right image and train efficient net b0 \n",
    "\n",
    "We also treat ODIR as multi-label problem instead of multi-class as originally it is officially a multi-label problem\n",
    "from https://odir2019.grand-challenge.org/dataset/\n",
    "> Note: one patient may contains one or multiple labels. \n",
    "\n",
    "We also want to explore binocular or siamese approach to train our model on both left and right fundus image pair. This has been researched in https://arxiv.org/html/2504.18046v3 DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular: Fundus Image Classification Guohao Huo, Zibo Lin, Zitong Wang, Ruiting Dai, Hao Tang paper to work well for fundus disease classification \n",
    "\n",
    "There are 3 advantages of use both eyes images instead of one eye image :\n",
    "- Symmetry: Diseases like Diabetes aren't \"accidents\" in one eye; they are systemic. If the AI sees it in both, it's a \"confirmed\" diagnosis.\n",
    "\n",
    "- Comparison: The left eye acts as a \"control\" for the right eye. AI can spot a tiny change by noticing how much it differs from the other eye.\n",
    "\n",
    "- Noise Reduction: Just like your two eyes help you see depth, two images help the AI ignore \"camera blur\" or \"dust\" on one lens that might look like a disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7e6c1",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7fd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q kagglehub torch torchvision scikit-learn pandas opencv-python tqdm wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a9960",
   "metadata": {},
   "source": [
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c344cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, multilabel_confusion_matrix, accuracy_score\n",
    "import kagglehub\n",
    "from tqdm import tqdm # tqdm for progress bars\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6af03",
   "metadata": {},
   "source": [
    "Download DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae4a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/ray/.cache/kagglehub/datasets/andrewmvd/ocular-disease-recognition-odir5k/versions/2\n"
     ]
    }
   ],
   "source": [
    "# 1. Download Dataset (Official ODIR-5K)\n",
    "path = kagglehub.dataset_download(\"andrewmvd/ocular-disease-recognition-odir5k\")\n",
    "print(\"Dataset path:\", path)\n",
    "IMG_DIR = os.path.join(path, \"ODIR-5K/ODIR-5K/Training Images\")\n",
    "CSV_PATH = os.path.join(path, \"full_df.csv\")\n",
    "IMG_SIZE = 512\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811c9f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spotÔºåmoderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>2_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>5_left.jpg</td>\n",
       "      <td>5_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "1   1           57        Male  1_left.jpg  1_right.jpg   \n",
       "2   2           42        Male  2_left.jpg  2_right.jpg   \n",
       "3   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "4   5           50      Female  5_left.jpg  5_right.jpg   \n",
       "\n",
       "                            Left-Diagnostic Keywords  \\\n",
       "0                                           cataract   \n",
       "1                                      normal fundus   \n",
       "2  laser spotÔºåmoderate non proliferative retinopathy   \n",
       "3                        macular epiretinal membrane   \n",
       "4             moderate non proliferative retinopathy   \n",
       "\n",
       "                Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
       "0                           normal fundus  0  0  0  1  0  0  0  0   \n",
       "1                           normal fundus  1  0  0  0  0  0  0  0   \n",
       "2  moderate non proliferative retinopathy  0  1  0  0  0  0  0  1   \n",
       "3       mild nonproliferative retinopathy  0  1  0  0  0  0  0  1   \n",
       "4  moderate non proliferative retinopathy  0  1  0  0  0  0  0  0   \n",
       "\n",
       "                                            filepath labels  \\\n",
       "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
       "1  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
       "2  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "3  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "4  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "\n",
       "                     target     filename  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0]  1_right.jpg  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0]  2_right.jpg  \n",
       "3  [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0]  5_right.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e383c0",
   "metadata": {},
   "source": [
    "## Ben Graham's Preprocessing\n",
    "\n",
    "This function implements the Ben Graham Preprocessing \n",
    "ref : \n",
    "- https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jQkkhlkAAAAJ&citation_for_view=jQkkhlkAAAAJ:sNmaIFBj_lkC\n",
    "- https://scholar.google.com/citations?user=jQkkhlkAAAAJ&hl=en\n",
    "- https://arxiv.org/abs/2303.00915 usuyama variation\n",
    "\n",
    "\n",
    "From https://medium.com/@astronomer.abdurrehman/enhancing-image-quality-for-machine-learning-ben-grahams-preprocessing-e795ad982abe\n",
    "the method described as followed\n",
    "<blockquote>\n",
    "\n",
    "The cv2.GauissanBlur takes an image, (0, 0) tuple automatically chooses a gaussian filter size based on sigmaX value which specifies the intensity of blur. Goal of using gaussian blur here is to reduce the noise and smooth out the fine details.\n",
    "\n",
    "The addWeighted function blends two images together using specified weights, the -4 here is the beta value which subtracts the blurred image from the original image and 128 is the gamma value that adjusts the brightness so that the image does not become too dark after subtraction.\n",
    "\n",
    "\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004c25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_odir_image(img, target_size=512):\n",
    "    \"\"\"\n",
    "    Combines Circular Cropping, Aspect-Ratio Resizing, and Padding.\n",
    "    \"\"\"\n",
    "    # 1. Load and initial crop to remove obvious black dead space\n",
    "    if img is None: return None\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Thresholding to find the retina boundary\n",
    "    _, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(mask)\n",
    "    \n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        img = img[y:y+h, x:x+w]\n",
    "\n",
    "    # 2. Letterbox Resize (Preserve Aspect Ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_size / max(h, w)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    \n",
    "    # Use INTER_AREA for high-quality downsampling\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # 3. Create Square Canvas and Center\n",
    "    final_img = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
    "    offset_y = (target_size - new_h) // 2\n",
    "    offset_x = (target_size - new_w) // 2\n",
    "    final_img[offset_y:offset_y+new_h, offset_x:offset_x+new_w] = resized\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e956c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usuyama_prep(img):\n",
    "    \"\"\"Enhances vessels and normalizes lighting.\"\"\"\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Circular Crop: Find non-black pixels and crop\n",
    "    img = resize_odir_image(img, target_size=IMG_SIZE)  # Crop to circular region\n",
    "    blurred = cv2.GaussianBlur(img, (0, 0), 10)\n",
    "    enhanced = cv2.addWeighted(img, 4, blurred, -4, 128)\n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54067d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usuyama_green_prep(img):\n",
    "    \"\"\"Extracts the green channel and normalizes.\"\"\"\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Circular Crop: Find non-black pixels and crop\n",
    "    img = resize_odir_image(img, target_size=IMG_SIZE)  # Crop to circular region\n",
    "    green_ch = img[:, :, 1]\n",
    "    blurred = cv2.GaussianBlur(green_ch, (0, 0), 10)\n",
    "    green_ben = cv2.addWeighted(green_ch, 4, blurred, -4, 128)\n",
    "    \n",
    "    # Convert to 3-channel for Model Input\n",
    "    return cv2.merge([green_ben, green_ben, green_ben])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d3b4b",
   "metadata": {},
   "source": [
    "On the fly image prep caused the training slowdown given the image need to be preprocessed repeatedly each time it is loaded. We speed up the process by performing preprocessing offline once and cache it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bd455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_offline_prep(df, raw_dir, img_prep_func, save_dir):\n",
    "    print(\"üöÄ Starting Offline Pre-processing (Ben Graham)...\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    all_images = pd.concat([df['Left-Fundus'], df['Right-Fundus']]).unique()\n",
    "    for img_name in tqdm(all_images):\n",
    "        save_path = os.path.join(save_dir, img_name)\n",
    "        load_path = os.path.join(raw_dir, img_name)\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"‚úÖ {save_path} already exists. Skipping.\")\n",
    "            continue\n",
    "        if not os.path.exists(load_path):\n",
    "            print(f\"‚ö†Ô∏è  Warning: {load_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "        img = cv2.imread(str(load_path))\n",
    "        # Ben Graham Logic\n",
    "        enhanced = img_prep_func(img)\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd0e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Offline Pre-processing (Ben Graham)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6716/6716 [04:16<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Offline Pre-processing (Ben Graham)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6716/6716 [04:03<00:00, 27.61it/s]\n"
     ]
    }
   ],
   "source": [
    "run_offline_prep(df, IMG_DIR, usuyama_prep, \"tmp/usuyama_prep\")\n",
    "run_offline_prep(df, IMG_DIR, usuyama_green_prep, \"tmp/usuyama_green_prep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
